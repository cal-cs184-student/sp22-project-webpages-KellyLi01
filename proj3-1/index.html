<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>  
    div.padded {  
      padding-top: 0px;  
      padding-right: 100px;  
      padding-bottom: 0.25in;  
      padding-left: 100px;  
    }  
  </style> 
<title>Jennifer Yang CS184-ABZ, Kelly Li CS184-AAR  |  CS 184</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<h1 align="middle">Assignment 3: PathTracer</h1>
<h2 align="middle">Jennifer Yang CS184-ABZ, Kelly Li CS184-AAR</h2>

    <div class="padded">
        <p>This project is rendering objects with light.</p>
        <o>
           <a href="https://cal-cs184-student.github.io/sp22-project-webpages-KellyLi01/proj3-1/index.html">https://cal-cs184-student.github.io/sp22-project-webpages-KellyLi01/proj3-1/index.html</a>

            <h2 align="middle">Part 1: Ray Generation and Intersection</h2>
            <h3>Ray Generation</h3>
            <p>
                Given a point in the normalized image, first translate it by (-0.5, -0.5) to get the image centered at (0, 0),
                then scale the point by <pre>(tan(0.5*hFov) * 2, tan(0.5*vFov)*2)</pre> to get the point (new_x, new_y) in camera space.
                For example, the point (0,0) gets translated into (-0.5, -0.5), then scaled to become (-tan(0.5*hFov), -tan(0.5*vFov)).
                The camera-to-world rotation matrix is then used on the ray (new_x, new_y, -1) to convert the ray to world space.
                The ray is then normalized to get the direction vector.
            </p>
            <h3>Pixel Sampling</h3>
            <p>
                To input pixels from unnormalized image space, we first normalized the x and y coordinates using transformations,
                then used rand01() with get_sample() to sample random coordinates within the (x,y) pixel.
                With these samples, we would generate the camera ray which intersects at that point using generate_ray()
                and use Monte Carlo over all the samples to calculate the pixel’s radiance.
            </p>
            <h3>Primitive Intersection</h3>
            <p>
                For the primitive intersection, the ray intersection algorithm for the given primitive is used.
                If the ray intersects(i.e. t >= 0 and other primitive-specific conditions are met),
                the ray’s max_t value is updated to prevent objects in the back from being visible from the camera.
            </p>
            <h3>Triangle Intersection Algorithm</h3>
            <p>
                According to barycentric coordinates, a point in a triangle can be described with respect to the triangle’s vertices with the equations
                <pre>P = alpha*P_0 + beta*P_1 + gamma*P_2</pre> <pre>alpha + beta + gamma = 1 and they are all >=0.</pre> If a ray R(t) = o + td
                has a point of intersection on the triangle, then o + td = P,
                thus we can plug the ray’s equation into the point-in-triangle equation, and if the t, alpha, beta, and gamma values are valid, then the ray properly intersects with the triangle.
                Since alpha + beta + gamma = 1, alpha can be set to (1 - beta - gamma).
                Rearranging the equation <pre>o + td = (1-beta-gamma)*P_0 + beta*P_1 + gamma*P_2</pre> gives us <pre>-td + (P_1-P_0)beta + (P_2-P_0)gamma = o-P_0</pre>
                This can be written as Mx = b, where <pre>M = [-d, P_1-P_0, P_2-P_0]</pre> <pre>x = [t, beta, gamma]^T</pre><pre>b = [o-P_0]</pre>
                Applying Cramer’s rule on the linear equation Mx=b gives us the Moller-Trumbore algorithm, which we use to find t, beta, and gamma.
                After getting the t, beta, and gamma values, if t < 0, beta < 0, beta > 1, gamma < 0, gamma > 1, or 1-beta-gamma < 0,
                then the ray does not intersect with the triangle. Otherwise, it intersects the triangle.

            </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/task1-spheres.png" width="480px" />
                            <figcaption align="middle">Normal shading on CBSpheres</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/task1-bench.png" width="480px" />
                            <figcaption align="middle">Normal shading on bench</figcaption>
                        </td>
                    </tr>
                    <tr>
                        <td align="middle">
                            <img src="images/task1-blob.png" width="480px" />
                            <figcaption align="middle">Normal shading on blob</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part1-cow.png" width="480px" />
                            <figcaption align="middle">Normal shading on cow</figcaption>
                        </td>
                    </tr>
                </table>
            </div>

            <h2 align="middle">Part 2: Bounding Volume Hierarchy</h2>
            <h3>BVH Construction Algorithm</h3>
            <p>
                We started by initializing a bounding box.
                We iterated through all our primitives,
                expanding the bounding box to include the primitive bounding boxes and finding the max and min x,y,z values.
                After looping through our primitives,
                we computed the average of our bounding boxes centroids
                and determined which axis had the greatest range of values in the bounding box.
                This axis would be the one we partition on later.
                Our splitting point heuristic was the average of bounding box centroids.
                If the number of primitives was greater than the max number of leaves variable given,
                we need to continue splitting.
                We used std::partition to split the primitives into new nodes,
                based on the axis we decided earlier.
                If any partitions are empty,
                we risk running into a segfault and slower runtime so we move one primitive over to the empty side.
                Then we recursively construct our left and right leaves.
                If we are at a leaf, we don’t do anything in addition to expanding the bounding box (explained above).
            </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part2-1-cow.gif" width="480px" />
                            <figcaption align="middle">The various BVHNodes of a cow</figcaption>
                        </td>
                    </tr>
                </table>
            </div>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part2-3-bench.png" width="480px" />
                            <figcaption align="middle">Bench rendered with BVH acceleration</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part2-3-blob.png" width="480px" />
                            <figcaption align="middle">Blob rendered with BVH acceleration</figcaption>
                        </td>
                    </tr>
                    <tr>
                        <td align="middle">
                            <img src="images/part2-3-lucy.png" width="480px" />
                            <figcaption align="middle">CBlucy rendered with BVH acceleration</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part2-3-max.png" width="480px" />
                            <figcaption align="middle">Maxplanck rendered with BVH acceleration</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <h3>Rendering Time Comparisons</h3>
            <p>
                We rendered both the blob and the bench during part 1 without BVH acceleration,
                and blob.dae took approximately 20 minutes to complete rendering without BVH,
                but took 13 seconds using BVH acceleration.
                Bench.dae took about 10 minutes to complete rendering without BVH acceleration,
                and took less than a second with BVH acceleration.
                CBLucy and MaxPlanck were close to impossible without BVH acceleration. With BVH acceleration,
                CBLucy took less than a second to complete and MaxPlanck took around 3 seconds to complete.
            </p>

            <h2 align="middle">Part 3: Direct Illumination</h2>
            <h3>Uniform Hemisphere Sampling Algorithm</h3>
            <p>
                We start by calculating our PDF,
                which is constant 1/2pi for uniform hemisphere sampling.
                We then loop num_sample times and use hemisphereSampler to sample a new unit direction, which will be w_i in object space coming out of hit_p.
                We then convert w_i to world space and create a new ray with an origin at our hit point
                (+ a small constant to offset floating point issues) and the world space w_i for its direction.
                We create a new intersection instance for this new ray, and if the ray intersects any objects (using BVHAccel’s intersect),
                we calculate the reflectance given our incoming and outgoing solid angles, radiance,
                and cosine theta (dot product of (0, 0, 1) and our sample in object space).
                We then add the reflectance / PDF to our Monte Carlo sum,
                which we then divide by num_samples and return after we finish looping num_sample times.

            </p>
            <h3>Importance Sampling Lights Algorithm</h3>
            <p>
                We loop through all the lights and keep track of how many samples we should take per light.
                If a light is a point light, num_samples = 1.
                If it is not a point light, we sample it num_samples = ns_area_light times.
                Next, we loop through the number of samples we want per light,
                use sample_L to calculate radiance and populate our dist_to_light, w_i in world space,
                and pdf for that sample.
                We create a new ray with the direction as w_i, hit_p as the origin,
                and the dist_to_light as the max_t. EPS_F is also used to prevent floating point issues.
                We create a new intersection for this ray as well.
                If our new intersection does not intersect with the ray we just made,
                there’s no shadow and we need to factor it into monte carlo.
                We also calculate cosine_theta using w_i translated to object space to see if it’s negative.
                If cosine_theta is negative, our light source is behind the object and we don’t need to add anything to our monte carlo radiance.
                For each sample, we calculate the radiance using w_out and w_i in object space (the same way we did for uniform hemisphere sampling),
                then divide the value by pdf * num_samples (so that point light is factored in properly).
                For each sample, we add the calculated radiance / (pdf * num_samples)
                to the total radiance to get the Monte Carlo Estimate of radiance by the end of looping through all the lights.


            </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part3-hemi-bunny_64_32.png" width="480px" />
                            <figcaption align="middle">CBbunny rendered with uniform hemisphere sampling</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part3-import-bunny_64_32.png" width="480px" />
                            <figcaption align="middle">CBbunny rendered with importance sampling</figcaption>
                        </td>
                    </tr>
                    <img src="images/part3-import-dragon_64_32.png" width="480px" />
                    <figcaption align="middle">Dragon rendered with importance sampling</figcaption>
                </table>
            </div>

            <h3>Various Light Rays with Importance Sampling</h3>
            <p>
                The noise level in soft shadows is much greater when rendering with 1 light ray,
                causing them to look more like sporadic dark pixels than shadows.
                As we render with more light rays,, the shape and overall clarity of the soft shadow improves.
            </p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part3-dragon_1_1.png" width="480px" />
                            <figcaption align="middle">1 light ray</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part3-dragon_1_4.png" width="480px" />
                            <figcaption align="middle">4 light rays</figcaption>
                        </td>
                    </tr>
                    <tr>
                        <td align="middle">
                            <img src="images/part3-dragon_1_16.png" width="480px" />
                            <figcaption align="middle">16 light ray</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part3-dragon_1_64.png" width="480px" />
                            <figcaption align="middle">64 light rays</figcaption>
                        </td>
                    </tr>
                </table>
            </div>


            <h2 align="middle">Part 4: Global Illumination</h2>
            <h3>Global Illumination Algorithm</h3>
            <p>
                We first set L_out to one-bounce radiance of intersection and CPDF to a termination probability of 0.35.
                From sample_f(), we get the brdf, w_i, and PDF.
                We initialize a new intersection and initialize a new ray with the direction as w_i, hit_p as the origin,
                and the depth as the parameter ray’s depth - 1. EPS_F is also used to prevent floating point issues.
                If the depth of the given ray is greater than 1 and the new_ray intersects and object,
                we use russian roulette with the cpdf to determine if we should continue calculating the ray’s bounces
                If our r.depth is equal to our max_ray_depth, we do not do russian roulette,
                thus guaranteeing at least one indirect bounce is calculated.
                We also do not divide our monte carlo radiance (brdf * radiance * cos_theta/PDF) by CPDF.
                Otherwise, we divide our monte carlo radiance by CPDF.
                The radiance in our monte carlo calculation is computed with the recursive call on this function,
                which we then add to L_out.
                Finally, L_out is returned as the radiance of the intersected point.

            </p>

            <h3>Images Rendered with Global Illumination</h3>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part4-global-bench_1024_4.png" width="480px" />
                            <figcaption align="middle">Bench rendered with global illumination</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part4-global-spheres_1024_4.png" width="480px" />
                            <figcaption align="middle">CBspheres-lambertian rendered with global illumination</figcaption>
                        </td>
                    </tr>
                </table>
            </div>

            <h3>Only Direct Illumination vs Only Indirect Illumination</h3>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part4-direct-sphere.png" width="480px" />
                            <figcaption align="middle">Spheres rendered with only direct illumination</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part4-indirect-sphere.png" width="480px" />
                            <figcaption align="middle">Spheres rendered with only indirect illumination</figcaption>
                        </td>
                    </tr>
                </table>
            </div>

            <h3>Changing max_ray_depth</h3>
            <p>
                As our ray depth increases, we can see that our images introduce more light into the box.
                This is evident in how the ceiling gradually transitions from being very dark to lit up,
                showing that more light is bouncing off materials within the box. <br />
                We can also see that there isn’t much difference between a max_ray_depth of 0 and 1
                because 1 is just once bounce (which is the same as when max_ray_depth = 0). <br />
                While the m=100 image is lighter than all the other max_ray_depth value images,
                it is not proportionally brighter due to the russian roulette terminating the ray bounce calculations,
                thus causing the calculation of all 100 bounces to be highly unlikely.

            </p>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part4-bunny_1024_4_0.png" width="480px" />
                            <figcaption align="middle">m = 0</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part4-bunny_1024_4_1.png" width="480px" />
                            <figcaption align="middle">m = 1</figcaption>
                        </td>

                    </tr>
                    <tr>
                        <td align="middle">
                            <img src="images/part4-bunny_1024_4_2.png" width="480px" />
                            <figcaption align="middle">m = 2</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part4-bunny_1024_4_3.png" width="480px" />
                            <figcaption align="middle">m = 3</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part4-bunny_1024_4_100.png" width="480px" />
                            <figcaption align="middle">m = 100</figcaption>
                        </td>
                    </tr>
                </table>
            </div>

            <h3>Changing sample-per-pixel rate</h3>
            <p>
                As our sample-per-pixel rate increases, 
                the overall noise/graininess of our image decreases. 
                The decreasing noise also causes the images’ shadows 
                to look lighter for higher sample-per-pixel rates.
            </p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part4_spheres_1_4.png" width="480px" />
                            <figcaption align="middle">s = 1</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part4_spheres_2_4.png" width="480px" />
                            <figcaption align="middle">s = 2</figcaption>
                        </td>

                    </tr>
                    <tr>
                        <td align="middle">
                            <img src="images/part4_spheres_4_4.png" width="480px" />
                            <figcaption align="middle">s = 4</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part4_spheres_8_4.png" width="480px" />
                            <figcaption align="middle">s = 8</figcaption>
                        </td>
                    </tr>
                    <tr>
                        <td align="middle">
                            <img src="images/part4_spheres_16_4.png" width="480px" />
                            <figcaption align="middle">s = 16</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part4_spheres_64_4.png" width="480px" />
                            <figcaption align="middle">s = 64</figcaption>
                        </td>
                    </tr>
                </table>
            </div>
            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part4_spheres_1024_4.png" width="480px" />
                            <figcaption align="middle">s = 1024</figcaption>
                        </td>
                    </tr>
                </table>
            </div>

            <h2 align="middle">Part 5: Adaptive Sampling</h2>
            <p>
                We initialize a couple of new variables (count, sum_one, and sum_squared) and set num_samples equal to 0. Count is used to see how many samples we have taken since the last batch. As we sample, we add the illuminance to sum_one and the illuminance squared to sum_squared. We increment count and num_samples. 
                Then, we check if our count is equal to samplesPerBatch. If it is, we calculate the mean using sum_one and num_samples and calculate the variance using sum_squared, sum_one, and num_samples. We then calculate the pixel convergence (I value in the spec) and check if that is less than or equal to our maxTolerance * mean. If it is, we break our loop and stop tracing more rays for this pixel. 
            </p>

            <div align="center">
                <table style="width=100%">
                    <tr>
                        <td align="middle">
                            <img src="images/part5-bunny.png" width="480px" />
                            <figcaption align="middle">Bunny rendered with adaptive sampling</figcaption>
                        </td>
                        <td align="middle">
                            <img src="images/part5-bunny_rate.png" width="480px" />
                            <figcaption align="middle">Bunny sample rate with adaptive sampling</figcaption>
                        </td>
                    </tr>
                </table>
            </div>

            <h2 align="middle">Partner Summary</h2>
            <p>
                We called on Zoom with one person coding and the other person watching / driving, switching off roles every so often. In general, we never worked alone so we were always collaborating. Overall, the project was pretty taxing and took a lot of hours, especially since we had a bug for quite some time that dramatically slowed down our rendering. There was also a period of time where all we were able to render was black squares (this was a separate bug from the one that slowed our rendering), so it was an adventure debugging the issue and pinpointing which part of our code was faulty. 
                We learned that small bugs can cause rendering times to dramatically increase and that we should always divide by floating points. 

            </p>

        </o></div>
</body>
</html>




